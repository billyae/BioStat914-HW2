{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 SVD for a Noisy Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix Shape: (100, 50)\n"
     ]
    }
   ],
   "source": [
    "# Generate the matrix\n",
    "\n",
    "N,M = 100,50\n",
    "\n",
    "# Form 2 random vectors\n",
    "u=np.random.rand(N,1)\n",
    "v=np.random.rand(M,1)\n",
    "\n",
    "# Compute the rank-1 matrix using outer product\n",
    "R_1 = u @ v.T\n",
    "\n",
    "# Calculate the Frobenius norm of this matrix\n",
    "R_f = np.linalg.norm(R_1, 'fro')\n",
    "\n",
    "noise_variance = 0.01 * R_f\n",
    "\n",
    "noise = np.random.normal(0, np.sqrt(noise_variance), (N,M)) \n",
    "\n",
    "R_ = R_1 + noise\n",
    "\n",
    "# Display the shape of the matrix\n",
    "\n",
    "print(\"The matrix Shape:\", R_.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U Shape: (100, 50)\n",
      "s Shape: (50,)\n",
      "V Shape: (50, 50)\n"
     ]
    }
   ],
   "source": [
    "# Decompose the matrix using SVD\n",
    "\n",
    "U1, s1, V1 = np.linalg.svd(R_, full_matrices=False)\n",
    "\n",
    "print(\"U Shape:\", U1.shape)\n",
    "\n",
    "print(\"s Shape:\", s1.shape)\n",
    "\n",
    "print(\"V Shape:\", V1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the matrix R using only the first singular value and the corresponidng singular vectors\n",
    "\n",
    "R_reconstructed = s1[0] * np.outer(U1[:,0], V1[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U_original Shape: [[-0.08465639 -0.72666733 -0.00614252 ... -0.00125815 -0.01037617\n",
      "   0.67820294]\n",
      " [-0.11146218  0.02206445  0.0461166  ... -0.00514486 -0.01868697\n",
      "   0.00619947]\n",
      " [-0.1382825  -0.18979262 -0.06258836 ... -0.11249273 -0.18736701\n",
      "  -0.25258603]\n",
      " ...\n",
      " [-0.14352204  0.09731988  0.14556701 ...  0.05277509  0.01800429\n",
      "   0.09337201]\n",
      " [-0.18286614  0.04777537  0.56919572 ... -0.10889249 -0.01610159\n",
      "   0.02145267]\n",
      " [-0.03709111  0.00093313 -0.03299787 ... -0.0451366   0.09285429\n",
      "  -0.00253355]]\n",
      "s_original Shape: [2.15300713e+01 2.15062500e-15 2.15062500e-15 2.15062500e-15\n",
      " 2.15062500e-15 2.15062500e-15 2.15062500e-15 2.15062500e-15\n",
      " 2.15062500e-15 2.15062500e-15 2.15062500e-15 2.15062500e-15\n",
      " 2.15062500e-15 2.15062500e-15 2.15062500e-15 2.15062500e-15\n",
      " 2.15062500e-15 2.15062500e-15 2.15062500e-15 2.15062500e-15\n",
      " 2.15062500e-15 2.15062500e-15 2.15062500e-15 2.15062500e-15\n",
      " 2.15062500e-15 2.15062500e-15 2.15062500e-15 2.15062500e-15\n",
      " 2.15062500e-15 2.15062500e-15 2.15062500e-15 2.15062500e-15\n",
      " 2.15062500e-15 2.15062500e-15 2.15062500e-15 2.15062500e-15\n",
      " 2.15062500e-15 2.15062500e-15 2.15062500e-15 2.15062500e-15\n",
      " 2.15062500e-15 2.15062500e-15 2.15062500e-15 2.15062500e-15\n",
      " 2.15062500e-15 2.15062500e-15 2.15062500e-15 2.15062500e-15\n",
      " 2.15062500e-15 5.33199532e-17]\n",
      "V_original Shape: [[-2.47927710e-02 -1.38759234e-01 -6.05751317e-02 ... -1.07112256e-01\n",
      "  -1.90066871e-02 -7.30933014e-02]\n",
      " [ 0.00000000e+00 -1.25893484e-01 -1.10534579e-01 ...  1.02525175e-01\n",
      "  -8.66094772e-03  1.20055239e-01]\n",
      " [ 0.00000000e+00 -3.18319978e-02  2.89108640e-02 ...  1.43314735e-03\n",
      "   3.91760257e-02  2.96965470e-02]\n",
      " ...\n",
      " [ 0.00000000e+00  1.25979434e-01 -1.18415630e-01 ...  7.14025665e-02\n",
      "   7.49847179e-02  3.79203883e-03]\n",
      " [ 0.00000000e+00 -5.77189581e-02  2.93357418e-01 ... -1.77377555e-02\n",
      "  -4.14760937e-02  5.90488318e-02]\n",
      " [ 9.99692612e-01 -3.44128373e-03 -1.50228715e-03 ... -2.65642619e-03\n",
      "  -4.71373337e-04 -1.81274270e-03]]\n"
     ]
    }
   ],
   "source": [
    "# calculate and output the original values of U and V\n",
    "\n",
    "U_orginal, s_original, V_original = np.linalg.svd(R_1, full_matrices=False)\n",
    "\n",
    "print(\"U_original Shape:\", U_orginal)\n",
    "\n",
    "print(\"s_original Shape:\", s_original)\n",
    "\n",
    "print(\"V_original Shape:\", V_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed U: [[-6.50665695e-02  2.09492012e-01  1.19701387e-02 ...  6.98470640e-03\n",
      "   2.82974468e-03 -9.68128566e-01]\n",
      " [-1.05575840e-01  7.48150215e-02  4.74005384e-02 ...  1.00900811e-01\n",
      "  -1.72478829e-02  2.48344094e-02]\n",
      " [-1.02932253e-01  3.14728178e-02  3.53124619e-02 ...  2.52801136e-01\n",
      "   4.07280328e-03  3.63305367e-02]\n",
      " ...\n",
      " [-1.10313373e-01  8.75014350e-02 -5.45398955e-02 ... -1.11684883e-01\n",
      "  -1.75853630e-01 -8.61989518e-04]\n",
      " [-1.95308088e-01 -2.10994990e-01  1.01905919e-01 ...  2.55047448e-02\n",
      "   3.36976179e-01 -4.46585724e-02]\n",
      " [-8.42752198e-02 -2.49296178e-01 -1.16643015e-01 ... -3.38866142e-02\n",
      "  -8.50586960e-02 -4.11574822e-02]]\n",
      "Reconstructed V: [[-1.62238013e-02 -1.28815215e-01 -3.31239772e-02 ... -7.12497626e-02\n",
      "   2.54461296e-02 -8.82746726e-02]\n",
      " [ 0.00000000e+00 -7.67619751e-02 -1.95218306e-02 ... -6.29389348e-02\n",
      "  -6.14522381e-03  1.31958618e-01]\n",
      " [ 0.00000000e+00  5.89378368e-02  8.56414617e-03 ...  1.67823013e-01\n",
      "  -2.60590486e-02 -8.59844055e-03]\n",
      " ...\n",
      " [ 0.00000000e+00 -4.52365556e-02 -1.06174259e-01 ... -7.67017417e-02\n",
      "  -1.95200261e-01  4.79902877e-02]\n",
      " [ 0.00000000e+00  3.54441243e-02  2.73940624e-01 ... -2.39778766e-02\n",
      "  -4.81354430e-02 -3.24949633e-02]\n",
      " [-9.99868385e-01  2.09014754e-03  5.37467562e-04 ...  1.15609415e-03\n",
      "  -4.12887291e-04  1.43233926e-03]]\n",
      "Reconstructed s: [2.22376706e+01 2.22169721e-15 2.22169721e-15 2.22169721e-15\n",
      " 2.22169721e-15 2.22169721e-15 2.22169721e-15 2.22169721e-15\n",
      " 2.22169721e-15 2.22169721e-15 2.22169721e-15 2.22169721e-15\n",
      " 2.22169721e-15 2.22169721e-15 2.22169721e-15 2.22169721e-15\n",
      " 2.22169721e-15 2.22169721e-15 2.22169721e-15 2.22169721e-15\n",
      " 2.22169721e-15 2.22169721e-15 2.22169721e-15 2.22169721e-15\n",
      " 2.22169721e-15 2.22169721e-15 2.22169721e-15 2.22169721e-15\n",
      " 2.22169721e-15 2.22169721e-15 2.22169721e-15 2.22169721e-15\n",
      " 2.22169721e-15 2.22169721e-15 2.22169721e-15 2.22169721e-15\n",
      " 2.22169721e-15 2.22169721e-15 2.22169721e-15 2.22169721e-15\n",
      " 2.22169721e-15 2.22169721e-15 2.22169721e-15 2.22169721e-15\n",
      " 2.22169721e-15 2.22169721e-15 2.22169721e-15 2.22169721e-15\n",
      " 2.22169721e-15 9.84542263e-17]\n"
     ]
    }
   ],
   "source": [
    "# calculate and output the Reconstructed values of U and V\n",
    "\n",
    "U_reconstructed, s_constructed, V_reconstructed = np.linalg.svd(R_reconstructed, full_matrices=False)\n",
    "\n",
    "print(\"Reconstructed U:\", U_reconstructed)\n",
    "\n",
    "print(\"Reconstructed V:\", V_reconstructed)\n",
    "\n",
    "print(\"Reconstructed s:\", s_constructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.08540524039884285\n",
      "RMSE_U: 0.1423131211660104\n",
      "RMSE_V: 0.19817176210417836\n"
     ]
    }
   ],
   "source": [
    "# Computer the Root Mean Squared Error between the original matrix R and the reconstructed matrix R_reconstructed \n",
    "\n",
    "RMSE = np.sqrt(np.mean((R_1 - R_reconstructed)**2))\n",
    "\n",
    "print(\"RMSE:\", RMSE)\n",
    "\n",
    "# Compute the Root Mean Squared Errors of U and V \n",
    "# From the value of U_original, V_original and U_reconstructed, V_reconstructed, there is no need to adjust the sign of the singular vectors when calculating the RMSE\n",
    "\n",
    "RMSE_U = np.sqrt(np.mean((U_orginal - U_reconstructed)**2))\n",
    "\n",
    "RMSE_V = np.sqrt(np.mean((V_original- V_reconstructed)**2))\n",
    "\n",
    "print(\"RMSE_U:\", RMSE_U)\n",
    "print(\"RMSE_V:\", RMSE_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The impact of noise:**\n",
    "\n",
    "1. Effect on the Matrix Reconstruction: The RMSE for the reconstructed matrix is pretty small, indicating that the reconstruction closely approximates the original matrix despite the added noise. This is potentially because the reconstruction uses only the first singular value and the corresponding singular vectors, which contains most information of the matrix. This filters out higher-order singular values, which captures a portion of the noise, reducing the effect of noise on the reconstructed matrix.  \n",
    "2. Effect on the Singular Vectors: The RMSE for the singular vectors suggests that the noise has introduced some discrepancy between the original and reconstructed singular vectors. Singular vectors associated with significant singular values are typically less affected by noise because they represent more prominent structural components of the matrix. But the loss indicates that noise might alter the direction slightly, resulting the overall discrepancies. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Matrix Factorization of an Imcomplete Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Matrix \n",
    "\n",
    "# Calculate the total number of elements and 30% of that\n",
    "total_elements = N * M\n",
    "num_missing = int(0.3 * total_elements)\n",
    "\n",
    "# Randomly select indices to set as missing\n",
    "missing_indices = np.unravel_index(\n",
    "    np.random.choice(total_elements, num_missing, replace=False), (N, M)\n",
    ")\n",
    "\n",
    "# Create a copy of the original matrix and set the missing values to nan\n",
    "\n",
    "R_missing = np.copy(R_1)\n",
    "\n",
    "R_missing [missing_indices] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 199.13892867024185\n",
      "Epoch: 10 Loss: 26.514630769703217\n",
      "Epoch: 20 Loss: 3.8713736755834796\n",
      "Epoch: 30 Loss: 0.5818592065935589\n",
      "Epoch: 40 Loss: 0.09068988128701874\n",
      "Epoch: 50 Loss: 0.014664976023926586\n",
      "Epoch: 60 Loss: 0.002457359750247406\n",
      "Epoch: 70 Loss: 0.0004260976587323207\n",
      "Epoch: 80 Loss: 7.636194278034394e-05\n",
      "Epoch: 90 Loss: 1.4129479257189108e-05\n",
      "Epoch: 100 Loss: 2.6965645672952626e-06\n",
      "Epoch: 110 Loss: 5.301398896761745e-07\n",
      "Epoch: 120 Loss: 1.0719106204163478e-07\n",
      "Epoch: 130 Loss: 2.2244196449008695e-08\n",
      "Epoch: 140 Loss: 4.726050062296373e-09\n",
      "Epoch: 150 Loss: 1.0252470167123422e-09\n",
      "Epoch: 160 Loss: 2.264641346552285e-10\n",
      "Epoch: 170 Loss: 5.0797292295502243e-11\n",
      "Epoch: 180 Loss: 1.1541751781420576e-11\n",
      "Epoch: 190 Loss: 2.650540858492429e-12\n"
     ]
    }
   ],
   "source": [
    "# SGD for matrix factorization\n",
    "\n",
    "def SGD_factorization(learning_rate, regularization, num_epochs, R_missing, output):\n",
    "\n",
    "    U_factorized = np.random.rand(N,1)\n",
    "    V_factorized = np.random.rand(M,1) # initialze the U and V matrices\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                \n",
    "                # Only consider the observed values\n",
    "                if not np.isnan(R_missing[i,j]):\n",
    "\n",
    "                    prediction = np.dot(U_factorized[i], V_factorized[j])\n",
    "                    error = R_missing[i,j] - prediction\n",
    "\n",
    "                    # Update the U and V matrices\n",
    "                    U_factorized[i] += learning_rate * (error * V_factorized[j] - regularization * U_factorized[i])\n",
    "                    V_factorized[j] += learning_rate * (error * U_factorized[i] - regularization * V_factorized[j]) \n",
    "                    \n",
    "        if output:\n",
    "            if epoch % 10 == 0:\n",
    "            \n",
    "                # Calculatre the total loss on observed entrices\n",
    "                observed_indices = ~np.isnan(R_missing)\n",
    "                loss = np.sum((R_missing[observed_indices] - (U_factorized @ V_factorized.T)[observed_indices])**2)\n",
    "                print(\"Epoch:\", epoch, \"Loss:\", loss)\n",
    "    \n",
    "    return U_factorized, V_factorized\n",
    "\n",
    "U_factorized,V_factorized = SGD_factorization(0.01, 0, 200, R_missing,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the factorized matrices U and V to reconstruct the matrix R\n",
    "\n",
    "R_reconstructed_missing = U_factorized @ V_factorized.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_missing: 1.662674717443701e-08\n"
     ]
    }
   ],
   "source": [
    "# Compute the RMSE between the original matrix R and the reconstructed matrix R_reconstructed\n",
    "\n",
    "RMSE_missing = np.sqrt(np.mean((R_1 - R_reconstructed_missing)**2))\n",
    "\n",
    "print(\"RMSE_missing:\", RMSE_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Missing Proportion: 0.1 ********\n",
      "RMSE of recoverd matrix: 2.0498713390486303e-15\n",
      "******* Missing Proportion: 0.2 ********\n",
      "RMSE of recoverd matrix: 1.4673931766634846e-15\n",
      "******* Missing Proportion: 0.3 ********\n",
      "RMSE of recoverd matrix: 1.959739858559067e-15\n",
      "******* Missing Proportion: 0.4 ********\n",
      "RMSE of recoverd matrix: 2.3659949996473913e-15\n",
      "******* Missing Proportion: 0.5 ********\n",
      "RMSE of recoverd matrix: 2.0342106441211844e-15\n",
      "******* Missing Proportion: 0.6 ********\n",
      "RMSE of recoverd matrix: 3.2093130276906625e-15\n",
      "******* Missing Proportion: 0.7 ********\n",
      "RMSE of recoverd matrix: 6.53815675203914e-10\n",
      "******* Missing Proportion: 0.8 ********\n",
      "RMSE of recoverd matrix: 2.426424989553833e-06\n",
      "******* Missing Proportion: 0.9 ********\n",
      "RMSE of recoverd matrix: 0.012485523144217336\n",
      "******* Missing Proportion: 0.95 ********\n",
      "RMSE of recoverd matrix: 0.08137264496784324\n",
      "******* Missing Proportion: 0.97 ********\n",
      "RMSE of recoverd matrix: 0.1682469591988202\n",
      "******* Missing Proportion: 0.99 ********\n",
      "RMSE of recoverd matrix: 0.24899322259586132\n"
     ]
    }
   ],
   "source": [
    "# Discuss other missing proportions for data generation and discuss their impacts in the reconstruction process\n",
    "\n",
    "# missing protions from 0.1 to 0.9\n",
    "\n",
    "missing_proportions = [0.1*i for i in range(1,10)]\n",
    "\n",
    "missing_proportions.extend([0.95,0.97,0.99])\n",
    "\n",
    "for missing_proportion in missing_proportions:\n",
    "\n",
    "    num_missing = int(missing_proportion * total_elements)\n",
    "\n",
    "    missing_indices = np.unravel_index(\n",
    "        np.random.choice(total_elements, num_missing, replace=False), (N, M)\n",
    "    )\n",
    "\n",
    "    R_missing = np.copy(R_1)\n",
    "    \n",
    "    R_missing[missing_indices] = np.nan\n",
    "\n",
    "    U_factorized,V_factorized = SGD_factorization(0.01, 0,1000, R_missing,False)\n",
    "\n",
    "    R_reconstructed_missing = U_factorized @ V_factorized.T\n",
    "\n",
    "    RMSE_missing = np.sqrt(np.mean((R_1 - R_reconstructed_missing)**2))\n",
    "\n",
    "    print(\"******* Missing Proportion:\", round(missing_proportion,2),\"********\")\n",
    "    print(\"RMSE of recoverd matrix:\", RMSE_missing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion impact of the missing value proportion on reconstructed matrix**: \n",
    "\n",
    "1. For the low and moderate missing value proportion such as 10% - 70%, the RMSE is very low, indicating that the factorization can approximate the missing value and the observed value accurately.  \n",
    "2. For the very high missing proportion such as 80% - 99%, the RMSE continues to increase. For the missing value proportion above 90%, the discrepancy of original and reconstructed matrix is notable, indicating the matrix factorization struggles to impute the missing value of the matrix when the matrix is extremely sparse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Singular Number: 1 ********\n",
      "RMSE of recovered matrix: 0.1789345727631257\n",
      "******* Singular Number: 2 ********\n",
      "RMSE of recovered matrix: 0.1657988250842047\n",
      "******* Singular Number: 3 ********\n",
      "RMSE of recovered matrix: 0.15250822927225222\n",
      "******* Singular Number: 4 ********\n",
      "RMSE of recovered matrix: 0.13887584136248748\n",
      "******* Singular Number: 5 ********\n",
      "RMSE of recovered matrix: 0.12449781589669884\n",
      "******* Singular Number: 6 ********\n",
      "RMSE of recovered matrix: 0.10956572965749556\n",
      "******* Singular Number: 7 ********\n",
      "RMSE of recovered matrix: 0.09305250762048164\n",
      "******* Singular Number: 8 ********\n",
      "RMSE of recovered matrix: 0.0745090721377148\n",
      "******* Singular Number: 9 ********\n",
      "RMSE of recovered matrix: 0.05167785365512812\n",
      "******* Singular Number: 10 ********\n",
      "RMSE of recovered matrix: 6.304889345978013e-16\n",
      "******* Singular Number: 20 ********\n",
      "RMSE of recovered matrix: 6.426193871953939e-16\n",
      "******* Singular Number: 30 ********\n",
      "RMSE of recovered matrix: 6.547843211891478e-16\n",
      "******* Singular Number: 40 ********\n",
      "RMSE of recovered matrix: 6.677966821959573e-16\n",
      "******* Singular Number: 50 ********\n",
      "RMSE of recovered matrix: 6.80474763334968e-16\n"
     ]
    }
   ],
   "source": [
    "# Generate Matrix with Rank 10\n",
    "\n",
    "N,M = 100,50\n",
    "\n",
    "full_rank_matrix = np.random.rand(N, M)\n",
    "    \n",
    "# Perform SVD decomposition\n",
    "U_10, s_10, Vt_10 = np.linalg.svd(full_rank_matrix, full_matrices=False)\n",
    "\n",
    "# Keep only the top `rank` singular values\n",
    "s_10[10:] = 0\n",
    "    \n",
    "# Reconstruct the matrix\n",
    "\n",
    "R_10 = U_10 @ np.diag(s_10) @ Vt_10\n",
    "\n",
    "# choose a moderate missing data proportions\n",
    "num_missing = int(0.3 * total_elements)\n",
    "\n",
    "missing_indices = np.unravel_index(\n",
    "    np.random.choice(total_elements, num_missing, replace=False), (N, M)\n",
    ")\n",
    "\n",
    "R_missing_10 = np.copy(R_10)\n",
    "\n",
    "R_missing_10[missing_indices] = np.nan\n",
    "\n",
    "# decompose the matrix using different number of singular components\n",
    "\n",
    "singular_components = [1,2,3,4,5,6,7,8,9,10, 20, 30, 40, 50]\n",
    "\n",
    "for K in singular_components:\n",
    "\n",
    "    U_reconstructed, s_constructed, V_reconstructed = np.linalg.svd(R_10, full_matrices=False)\n",
    "    \n",
    "    s_constructed[K:] = 0\n",
    "\n",
    "    R_reconstructed_k = U_reconstructed @ np.diag(s_constructed) @ V_reconstructed\n",
    "\n",
    "    RMSE_missing = np.sqrt(np.mean((R_10 - R_reconstructed_k)**2))\n",
    "\n",
    "    print(\"******* Singular Number:\", K ,\"********\")\n",
    "    print(\"RMSE of recovered matrix:\", RMSE_missing)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**:   \n",
    "I use the a rank-10 matrix with 30% missing values.\n",
    "1. For the number of singular components smaller than or equal to the Rank of the matrix. As the number of singular components increases, the reconstruction effect increases because for the kth singular compoents (k<=10), the singular components contain part information of the matrix. And the MSE becomes very small as the number of singualr components is equal to the Rank of the matrix because we use nearly all useful information to reconstruct the matrix.  \n",
    "2. For the number of singular values bigger than the Rank of the matrix. As the number of singular value increases, the reconstruction effect remains stable because singular values after the 10th are quite small so there is little information in those singular components of the matrix. So there is no improvements for reconstruction using k th singular components (k>10).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Matrix Factorization with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of elements and 30% of that\n",
    "total_elements = N * M\n",
    "\n",
    "num_missing = int(0.8 * total_elements)\n",
    "\n",
    "# Randomly select indices to set as missing\n",
    "missing_indices = np.unravel_index(\n",
    "    np.random.choice(total_elements, num_missing, replace=False), (N, M)\n",
    ")\n",
    "\n",
    "# Create a copy of the original matrix and set the missing values to nan\n",
    "\n",
    "R_missing = np.copy(R_1)\n",
    "\n",
    "R_missing[missing_indices] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(R_missing).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank-one factorization using regularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_reconstrcuion [[0.04518783 0.25290654 0.11041299 ... 0.19522499 0.03464141 0.13322169]\n",
      " [0.05949556 0.3329838  0.14537282 ... 0.25703866 0.04560984 0.17540339]\n",
      " [0.07381104 0.41310444 0.1803516  ... 0.31888582 0.05658422 0.21760794]\n",
      " ...\n",
      " [0.07660827 0.42875993 0.18718641 ... 0.33097069 0.0587286  0.22585466]\n",
      " [0.09760982 0.5463011  0.2385021  ... 0.42170371 0.07482858 0.28777094]\n",
      " [0.0197984  0.11080736 0.04837586 ... 0.08553502 0.01517763 0.05836916]]\n",
      "R_original [[0.04518875 0.25291064 0.11040776 ... 0.19522902 0.03464269 0.1332241 ]\n",
      " [0.05949741 0.33299283 0.14536751 ... 0.25704677 0.04561203 0.17540847]\n",
      " [0.07381383 0.41311843 0.18034622 ... 0.31889804 0.05658732 0.21761572]\n",
      " ...\n",
      " [0.07661065 0.42877155 0.18717957 ... 0.33098113 0.05873142 0.22586121]\n",
      " [0.09761214 0.5463119  0.23849163 ... 0.42171392 0.07483163 0.28777718]\n",
      " [0.01979887 0.11080956 0.04837374 ... 0.08553709 0.01517825 0.05837043]]\n",
      "RMSE of recovered matrix: 3.285609057185665e-05\n"
     ]
    }
   ],
   "source": [
    "# The result of Rank-one factorization using regularization\n",
    "\n",
    "# set regularization to 0.1 as an example\n",
    "\n",
    "U_factorized,V_factorized = SGD_factorization(0.01,1e-5, 1000, R_missing,False)\n",
    "\n",
    "R_reconstructed_missing = U_factorized @ V_factorized.T\n",
    "\n",
    "RMSE_missing = np.sqrt(np.mean((R_1 - R_reconstructed_missing)**2))\n",
    "\n",
    "print(\"R_reconstrcuion\", R_reconstructed_missing)\n",
    "\n",
    "print(\"R_original\",R_1)\n",
    "\n",
    "print(\"RMSE of recovered matrix:\", RMSE_missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion the selection of lamda on the reconstruction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Regularization: 0.0 ********\n",
      "RMSE of recovered matrix: 1.903031548464582e-05\n",
      "******* Regularization: 1e-07 ********\n",
      "RMSE of recovered matrix: 1.2540066835041894e-05\n",
      "******* Regularization: 2e-07 ********\n",
      "RMSE of recovered matrix: 5.130881445049577e-06\n",
      "******* Regularization: 3e-07 ********\n",
      "RMSE of recovered matrix: 5.496409683986112e-07\n",
      "******* Regularization: 4e-07 ********\n",
      "RMSE of recovered matrix: 5.344890136547401e-06\n",
      "******* Regularization: 5e-07 ********\n",
      "RMSE of recovered matrix: 1.0730243046580843e-05\n",
      "******* Regularization: 6e-07 ********\n",
      "RMSE of recovered matrix: 2.1021034504679266e-05\n",
      "******* Regularization: 7e-07 ********\n",
      "RMSE of recovered matrix: 9.258896347500448e-06\n",
      "******* Regularization: 8e-07 ********\n",
      "RMSE of recovered matrix: 9.1804264710524e-06\n",
      "******* Regularization: 9e-07 ********\n",
      "RMSE of recovered matrix: 6.120092060473727e-06\n",
      "******* Regularization: 1e-06 ********\n",
      "RMSE of recovered matrix: 3.3281929747496266e-06\n"
     ]
    }
   ],
   "source": [
    "lamda_all= [1e-7* i for i in range(0,11)]\n",
    "\n",
    "for lamda in lamda_all:\n",
    "    \n",
    "    U_factorized,V_factorized = SGD_factorization(0.01, lamda, 1000, R_missing,False)\n",
    "\n",
    "    R_reconstructed_missing = U_factorized @ V_factorized.T\n",
    "\n",
    "    RMSE_missing = np.sqrt(np.mean((R_1 - R_reconstructed_missing)**2))\n",
    "\n",
    "    print(\"******* Regularization:\", lamda ,\"********\")\n",
    "    print(\"RMSE of recovered matrix:\", RMSE_missing)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**:  \n",
    "I select lambda from 1e-7 to 1e-6.  \n",
    "1. When the lambda is small such as 1e-7 and 2e-7, the regularization term has minimal effect, allowing U and V to fit the observed entries of R more closely. This increases the risk of overfitting. When the lambda is below 3e-7, the effect of reconstruction with regularization is similar to the effect of no regularization reconstruction.  \n",
    "2. When the lambda is moderate such as 3e-7, the regularization term could balance the generalization ability of learning to the observed entries and fittiing performance on the observed entries. So the RMSE is smaller than RMSE without regularization.  \n",
    "3. When the lambda is large such as bigger than 4e-7, the generalization ability arises but the regularization term dominates the objective function, causing the values in U and V to be smaller in magnitude. So the factorization suffers a underfitting and impact the overall effect of missing value imputation and factorization reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate and compare the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I compared the RMSE of recovered matrix, U and V between using regularization and no regularization. We use the regularization parameter as 3e-7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the recovered matrix with regulrization: 2.1122483841265654e-06\n",
      "RMSE of the U with regularization 0.003884774457684544\n",
      "RMSE of the V with regularization 0.0040542834453287544\n"
     ]
    }
   ],
   "source": [
    "# Calculate the RMSE of the recovere matrix\n",
    "\n",
    "U_factorized,V_factorized = SGD_factorization(0.01,3e-7, 1000, R_missing,False)\n",
    "\n",
    "R_reconstructed_missing = U_factorized @ V_factorized.T\n",
    "\n",
    "RMSE_missing = np.sqrt(np.mean((R_1 - R_reconstructed_missing)**2))\n",
    "\n",
    "print(\"RMSE of the recovered matrix with regulrization:\", RMSE_missing)\n",
    "\n",
    "print(\"RMSE of the U with regularization\", np.sqrt(np.mean((u - U_factorized)**2)))\n",
    "\n",
    "print(\"RMSE of the V with regularization\", np.sqrt(np.mean((v - V_factorized)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the recovered matrix with no regularization: 7.29834679081841e-06\n",
      "RMSE of the U with no regularization 0.00865926886323159\n",
      "RMSE of the V with no regularization 0.008830485668457294\n"
     ]
    }
   ],
   "source": [
    "U_factorized_noreg,V_factorized_noreg = SGD_factorization(0.01,0, 1000, R_missing,False)\n",
    "\n",
    "R_reconstructed_missing_noreg = U_factorized_noreg @ V_factorized_noreg.T\n",
    "\n",
    "RMSE_missing = np.sqrt(np.mean((R_1 - R_reconstructed_missing_noreg)**2))\n",
    "\n",
    "print(\"RMSE of the recovered matrix with no regularization:\", RMSE_missing)\n",
    "\n",
    "print(\"RMSE of the U with no regularization\", np.sqrt(np.mean((u - U_factorized_noreg)**2)))\n",
    "\n",
    "print(\"RMSE of the V with no regularization\", np.sqrt(np.mean((v - V_factorized_noreg)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**:  \n",
    "1. Regularization effect on the recoverd matrix. For the moderate regularization hyperparameter, the RMSE of regularization on the recovered matrix is lower than with no regularization. It shows that moderate regularization can fit the observed data well with good generalizing ability for the reconstruction on matrix.  \n",
    "2. Regularization effect on the recoverd singular vector. For the moderate regularization hyperparemeter, the RMSE of regularization on the recovered singular vector is smaller than with no regularization. I shows that moderate regularization can fit the observed data well though it constrains the magnitude of the recovered singular vector. It predicts the singular vectors well and as a result, the multiplication of those singular vectors predicts the overall matrix well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "ratings_list = [i.strip().split(\"::\") for i in open('ratings.dat', 'r').readlines()]\n",
    "users_list = [i.strip().split(\"::\") for i in open('users.dat', 'r').readlines()]\n",
    "movies_list = [i.strip().split(\"::\") for i in open('movies.dat', 'r', encoding=\"ISO-8859-1\").readlines()]\n",
    "ratings = np.array(ratings_list)\n",
    "users = np.array(users_list)\n",
    "movies = np.array(movies_list)\n",
    "ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID','Rating', 'Timestamp'])\n",
    "movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n",
    "movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserID MovieID Rating  Timestamp\n",
       "0      1    1193      5  978300760\n",
       "1      1     661      3  978302109\n",
       "2      1     914      3  978301968\n",
       "3      1    3408      4  978300275\n",
       "4      1    2355      5  978824291"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                               Title                        Genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MovieID</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "MovieID  1 10 100 1000 1002 1003 1004 1005 1006 1007  ... 99 990 991 992 993  \\\n",
       "UserID                                                ...                      \n",
       "1        5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "10       5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "100      0  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1000     5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1001     4  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "\n",
       "MovieID 994 996 997 998 999  \n",
       "UserID                       \n",
       "1         0   0   0   0   0  \n",
       "10        0   0   0   0   0  \n",
       "100       0   0   0   0   0  \n",
       "1000      0   0   0   0   0  \n",
       "1001      0   0   0   0   0  \n",
       "\n",
       "[5 rows x 3706 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df = ratings_df.pivot(index = 'UserID', columns ='MovieID', values = 'Rating').fillna(0)\n",
    "R_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Recover rating matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MovieID</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "MovieID  1 10 100 1000 1002 1003 1004 1005 1006 1007  ... 99 990 991 992 993  \\\n",
       "UserID                                                ...                      \n",
       "1        5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "10       5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "100      0  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1000     5  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "1001     4  0   0    0    0    0    0    0    0    0  ...  0   0   0   0   0   \n",
       "\n",
       "MovieID 994 996 997 998 999  \n",
       "UserID                       \n",
       "1         0   0   0   0   0  \n",
       "10        0   0   0   0   0  \n",
       "100       0   0   0   0   0  \n",
       "1000      0   0   0   0   0  \n",
       "1001      0   0   0   0   0  \n",
       "\n",
       "[5 rows x 3706 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create a dictionary for quick lookup of actual ratings\n",
    "ratings_dict = {(row['UserID'], row['MovieID']): row['Rating'] for _, row in ratings_df.iterrows()}\n",
    "\n",
    "# Step 2: Define a function to replace 0s in R_df with values from ratings_dict if they exist\n",
    "def impute_rating(user_id, movie_id, rating):\n",
    "    # Check if the current rating is 0 and if there is an actual rating in ratings_dict\n",
    "    if rating == 0:\n",
    "        return ratings_dict.get((user_id, movie_id), rating)\n",
    "    return rating\n",
    "\n",
    "# Step 3: Apply the impute function to each element in R_df\n",
    "R_df2 = R_df.apply(lambda row: [impute_rating(row.name, col, row[col]) for col in R_df.columns], axis=1, result_type='broadcast')\n",
    "\n",
    "# Convert R_df back to a DataFrame with the correct columns\n",
    "R_df2 = pd.DataFrame(R_df2, index=R_df.index, columns=R_df.columns)\n",
    "\n",
    "# Display the first few rows of the imputed R_df\n",
    "R_df2.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
